[模块3:PCA实现] 二:PCA主成分分析法,自定义函数简写版
import numpy as np
class PCA():
    def __init__(self, n_components):
        self.n_components = n_components

    def fit_transform(self, X):
        self.n_features_ = X.shape[1]
        # 求协方差矩阵
        X = X - X.mean(axis=0)
        self.covariance = np.dot(X.T, X) / X.shape[0]
        # 求协方差矩阵的特征值和特征向量
        eig_vals, eig_vectors = np.linalg.eig(self.covariance)
        # 获得降序排列特征值的序号
        idx = np.argsort(-eig_vals)
        # 降维矩阵
        self.components_ = eig_vectors[:, idx[:self.n_components]]
        # 对X进行降维
        return np.dot(X, self.components_)

# 调用
pca = PCA(n_components=2)
X = np.array([[15, 12, 10],
              [12, 8, 9],
              [12, 8, 9],
              [6, 9, 16],
              [5, 8, 10],
              [4, 22, 16],
              [6, 10, 12],
              [5, 7, 11],
              [18, 12, 14],
              [10, 10, 12]])
newX = pca.fit_transform(X)
print(newX)  # 输出降维后的数据

#  [模块3:PCA实现] 三:PCA主成分分析法,直接调用接口
import numpy as np
from sklearn.decomposition import PCA
X = np.array([[-1,2,66,-1], [-2,6,58,-1], [-3,8,45,-2], [1,9,36,1], [2,10,62,1], [3,5,83,2]])  #导入数据，维度为4
pca = PCA(n_components=2)   #降到2维
pca.fit(X)                  #训练
newX=pca.fit_transform(X)   #降维后的数据
PCA(copy=True, n_components=2, whiten=False)
print(pca.explained_variance_ratio_)  #输出贡献率
print(newX)                  #输出降维后的数据
